__________________________________________________________________________КАК КАКАТЬ______________________________________________________________________________

1. Скачать VS Code; 

2. Нажать File в левом углу экрана;

3. Open Folder;

4. Открыть проект TrackerVT; 

5. Поставить виртуальное окружение - папочка venv; (Почитай что такое виртуальное окружение в Python); 

6. Поставить все необходимые библиотеки при помощи команды pip3 install название_библиотеки:
   - pytorch (Если есть CUDA и GPU: pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118);  
   - ultralytics; 
   - opencv-python; (если будет ошибка: python-opencv);
   - matplotlib;
   - numpy;

7. Чтобы запустить на predict, заходим в файл run.py - и в параметре input_video_path указываем путь до нашего видео;

8. Чтобы запустить на train (обучение): 
   - Заходишь в data.yaml, чекаешь что пути указаны верно в этом файле: то есть пути до train, test, valid указаны верно; А также names указаны верно;
   - Если всё ок, то в tracker/train.py в аргументе указываем путь yaml файла. То есть: data=r"./data.yaml"; 
   - Запускаем функцию run.py;
   - Ждем завершения работы;

ВАЖНАЯ РЕМАРКА: Модели (тушки с 20 млн. параметров надо всегда запускать на GPU, особенно на обучение); 


9. Есть модели на YOLO, а есть RTDETR, если не запускается на predict / train, то возможная причина - аргумент model_type в файле tracker/drone_tracker.py, а именно надо указать либо YOLO, либо RTDETR

10. Чтобы загрузить модель в tracker, необходимо в файле tracker/drone_tracker.py в аргументе model_path указать абсолютный путь до модели; Путь до модели: в конце расширение .pt; 

11. В папке weights находятся (базовые) модели от ultralytics (их для загружаешь для обучения);  Для обучения на своих данных берешь всегда модели из папки weights;

12. Куда сохраняется обученная тобою модель: в tracker/train.py есть аргумент project  - туда и сохраняется; 

__________________________________________________________________________ЧТО МОЖНО УЛУЧШИТЬ__________________________________________________________________________

1. Обучать разные модели: YOLOv8m, YOLOv9, RTDETR на объединённом датасете tracker_V1, tracker_V2;

2. Тестировать на разных метриках; По итогам тестов на метриках а также на эталонных видосах выбирать лучшую модель по соотношению скорость-качество;

3. Запилить работу модели из Docker-контейнера;

4. Когда придут новые бобры, пусть дальше собирают данные для классов (чтобы не было дисбаланса классов);

5. Внедрить/Добавить фишечки для работы модели из локального сервера в Flask (например);

6. Протестировать на полигоне работу нейросети; 

7. Внедрить нейронку в NVIDIA Jetson (или же в аналоги если будет слишком дорого); 


_______________________________________________________________________________________________________________________________________________________________________



